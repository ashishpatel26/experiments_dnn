{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pECE results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Latex tables and CD-diagrams for p-confidence-ECE and p-classwise-ECE.\n",
    "\n",
    "1. Models need to be trained and tuned for calibrators\n",
    "2. The \"Dirichlet - Final Results\" notebook should be runned in order to get all_results which is used for generate_pECE.py\n",
    "3. pECE results for confidence ECE and classwise ECE should be generated using scripts in folder pECE_generation\n",
    "4. Put the tunings in correct folders and run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports to get \"utility\" package\n",
    "import sys\n",
    "from os import path\n",
    "sys.path.append( path.dirname( path.dirname( path.abspath(\"calibration\") ) ) )\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from calibration.cal_methods import evaluate, cal_results, TemperatureScaling, MatrixScaling, LogisticCalibration, VectorScaling_NN, softmax\n",
    "from dirichlet import FullDirichletCalibrator\n",
    "import pickle\n",
    "from utility.unpickle_probs import unpickle_probs\n",
    "from utility.evaluation import pECE, classwise_ECE, full_ECE, score_sampling\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = join('..', '..', 'logits')\n",
    "files_10 = ('probs_resnet_wide32_c10_logits.p', 'probs_densenet40_c10_logits.p',\n",
    "            'probs_lenet5_c10_logits.p', 'probs_resnet110_SD_c10_logits.p',\n",
    "           'probs_resnet110_c10_logits.p', 'probs_resnet152_SD_SVHN_logits.p',\n",
    "           'logits_pretrained_c10_logits.p', 'logits_pretrained_mnist_logits.p',\n",
    "           'logits_pretrained_svhn_logits.p')\n",
    "\n",
    "files_100 = ('probs_resnet_wide32_c100_logits.p', 'probs_densenet40_c100_logits.p',\n",
    "             'probs_lenet5_c100_logits.p', 'probs_resnet110_SD_c100_logits.p',\n",
    "             'probs_resnet110_c100_logits.p', 'logits_pretrained_c100_logits.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pECE_cw = join(\"..\", \"..\", \"tunings_all\", \"generated_pECE\", \"classwise_ECE\")\n",
    "path_pECE_guo = join(\"..\", \"..\", \"tunings_all\", \"generated_pECE\", \"guo_ECE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_results2(path, ext = \".p\"):\n",
    "    \n",
    "    file_path = join(path, \"*\" + ext)\n",
    "    files = glob.glob(file_path)\n",
    "\n",
    "    dfs_list = []\n",
    "\n",
    "    for fname in files:\n",
    "        with open(fname, \"rb\") as f:\n",
    "            df = pickle.load(f)  \n",
    "            dfs_list.append(df)\n",
    "            \n",
    "    df_tuning = pd.concat(dfs_list, sort=False)\n",
    "    \n",
    "    return df_tuning.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_result_df(path):\n",
    "    df_gen = read_in_results2(path)\n",
    "    df_gen['Method'].fillna(df_gen['method'], inplace=True)\n",
    "    df_gen['pECE'].fillna(df_gen['pECE_ens'], inplace=True)\n",
    "    \n",
    "    df_gen.drop(columns=[\"method\", \"pECE_ens\"], inplace=True)\n",
    "    \n",
    "    return df_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>pECE</th>\n",
       "      <th>L2</th>\n",
       "      <th>mu</th>\n",
       "      <th>Method</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet40_c10</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>mat_scale_l2_mu_off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet40_c100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>mat_scale_l2_mu_off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenet5_c10</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mat_scale_l2_mu_off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lenet5_c100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>mat_scale_l2_mu_off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrained_c10</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>mat_scale_l2_mu_off</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name    pECE       L2            mu               Method  index\n",
       "0   densenet40_c10  0.0000   250.00       0.00010  mat_scale_l2_mu_off    NaN\n",
       "1  densenet40_c100  0.0000     2.50   10000.00000  mat_scale_l2_mu_off    NaN\n",
       "2       lenet5_c10  0.0501     0.10       0.00001  mat_scale_l2_mu_off    NaN\n",
       "3      lenet5_c100  0.0000     0.25       0.01000  mat_scale_l2_mu_off    NaN\n",
       "4   pretrained_c10  0.0114  1000.00  100000.00000  mat_scale_l2_mu_off    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cw = gen_result_df(path_pECE_cw)\n",
    "df_cw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>pECE</th>\n",
       "      <th>Method</th>\n",
       "      <th>L2</th>\n",
       "      <th>mu</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet_wide32_c10</td>\n",
       "      <td>0.059</td>\n",
       "      <td>dir_diag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>densenet40_c10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dir_diag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lenet5_c10</td>\n",
       "      <td>0.029</td>\n",
       "      <td>dir_diag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet110_SD_c10</td>\n",
       "      <td>0.061</td>\n",
       "      <td>dir_diag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet110_c10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>dir_diag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name   pECE    Method  L2  mu  index\n",
       "0  resnet_wide32_c10  0.059  dir_diag NaN NaN    NaN\n",
       "1     densenet40_c10  0.000  dir_diag NaN NaN    NaN\n",
       "2         lenet5_c10  0.029  dir_diag NaN NaN    NaN\n",
       "3   resnet110_SD_c10  0.061  dir_diag NaN NaN    NaN\n",
       "4      resnet110_c10  0.000  dir_diag NaN NaN    NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guo = read_in_results2(path_pECE_guo)\n",
    "df_guo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dir_diag', 'dir_l2', 'dir_l2_mu', 'dir_l2_mu_off', 'dir_l2_off',\n",
       "       'dir_vec_scale', 'mat_scale_l2_mu_off', 'mat_scale_l2_mu',\n",
       "       'mat_scale_l2_off', 'mat_scale_l2', 'temp_scale', 'vec_scale',\n",
       "       'uncal'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guo.Method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mat_scale_l2_mu_off', 'mat_scale_l2_mu', 'mat_scale_l2_off',\n",
       "       'mat_scale_l2', 'dir_diag', 'dir_l2', 'dir_l2_mu', 'dir_l2_off',\n",
       "       'dir_l2_mu_off', 'dir_vec_scale', 'temp_scale', 'vec_scale',\n",
       "       'uncal'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cw.Method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_sorted = ['temp_scale', 'vec_scale', 'dir_diag', \n",
    "                  'dir_l2', \"mat_scale_l2\", \n",
    "                  'dir_l2_mu', \"mat_scale_l2_mu\",\n",
    "                  'dir_l2_off', \"mat_scale_l2_off\",\n",
    "                  'dir_l2_mu_off', \"mat_scale_l2_mu_off\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guo.pivot_table(index=\"Name\", columns=\"Method\", values=\"pECE\")[methods_sorted].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cw.pivot_table(index=\"Name\", columns=\"Method\", values=\"pECE\")[methods_sorted].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_new = ['c10_densenet40', 'c100_densenet40', 'c10_lenet5', 'c100_lenet5', 'c10_convnet', 'c100_convnet', 'mnist_mlp',\n",
    "             'SVHN_convnet', 'c10_resnet110_SD', 'c100_resnet110_SD', 'c10_resnet110', 'c100_resnet110', 'SVHN_resnet152_SD',\n",
    "             'c10_resnet_wide32', 'c100_resnet_wide32']\n",
    "\n",
    "models_sorted = ['c10_convnet', 'c10_densenet40', 'c10_lenet5', 'c10_resnet110', 'c10_resnet110_SD', 'c10_resnet_wide32',\n",
    "                 'c100_convnet', 'c100_densenet40', 'c100_lenet5', 'c100_resnet110', 'c100_resnet110_SD', 'c100_resnet_wide32',\n",
    "                 'mnist_mlp', 'SVHN_convnet', 'SVHN_resnet152_SD']\n",
    "\n",
    "methods_sorted = ['uncal', 'temp_scale', \"dir_l2\", 'dir_l2_mu_off', 'vec_scale', \"mat_scale_l2_mu_off\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c10_convnet', 'c10_densenet40', 'c10_lenet5', 'c10_resnet110', 'c10_resnet110_SD', 'c10_resnet_wide32', 'c100_convnet', 'c100_densenet40', 'c100_lenet5', 'c100_resnet110', 'c100_resnet110_SD', 'c100_resnet_wide32', 'mnist_mlp', 'SVHN_convnet', 'SVHN_resnet152_SD']\n"
     ]
    }
   ],
   "source": [
    "print(models_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex(dfs, methods_sorted, value = \"Loss\", round_to = 2, start = 4, start_w = 1, max_is_better = False, \n",
    "              index=True, multiplier = 1):\n",
    "    df_temp = dfs.pivot_table(index=\"Name\", columns=\"Method\", values=value)[methods_sorted] #.to_clipboard()\n",
    "    \n",
    "    df_temp.index = index_new\n",
    "    df_temp = df_temp.reindex(models_sorted)\n",
    "    \n",
    "    df_ranks = df_temp.rank(axis=1, ascending=max_is_better)\n",
    "    df_temp = (df_temp*multiplier).round(round_to)\n",
    "    \n",
    "    # Get latex lines\n",
    "    str_latex = df_temp.to_latex(index=index)\n",
    "    latex_lines = str_latex.splitlines()\n",
    "\n",
    "    ## Get average ranks line with \"midrule\"\n",
    "    avg_ranks = \" & \".join(map(str, df_ranks.mean().values.round(2)))\n",
    "    column_name_avg_rank = \"\" if not index else \" avg rank & \"\n",
    "    avg_ranks_str = \"\\\\midrule \\n\" + column_name_avg_rank + avg_ranks + \"\\\\\\\\\"\n",
    "    \n",
    "    \n",
    "    if latex_lines[0][-8] == \"l\":\n",
    "        end_piece = \"|c|ccc|cc}\"\n",
    "    else:\n",
    "        end_piece = \"c|ccc|cc}\"\n",
    "\n",
    "    first_line = latex_lines[0][:-7] + end_piece  # TODO based on column numbers\n",
    "    #latex_lines[0]\n",
    "\n",
    "    header_str_extra = \"\" if not index else \" & \"\n",
    "    header_str = [\"\\\\begin{table}\",\n",
    "                  \"\\\\centering\",\n",
    "                  \"\\\\captionof{table}{%s}\" % value,\n",
    "                  \"\\\\tiny\",\n",
    "                  first_line,\n",
    "                  \"\\\\toprule\",\n",
    "                  \"%s       & \\\\multicolumn{3}{c}{general-purpose calibrators} & \\\\multicolumn{2}{c}{neural-specific calibrators}\\\\\\\\ \" % header_str_extra,\n",
    "                  \"%s Uncal &  TempS &  Dir-L2 &  Dir-ODIR &  VecS & MS-ODIR \\\\\\\\\" % header_str_extra,\n",
    "                  \"\\\\midrule\"]\n",
    "    \n",
    "    tail_str = [\"\\\\normalsize\",\n",
    "                \"\\\\label{table:res:dnn:%s}\" % value.lower(),\n",
    "                \"\\hfill\",\n",
    "                \"\\end{table}\"]\n",
    "\n",
    "    for i, line in enumerate(latex_lines[start:-2]):  # Starting line and ending line, may need some changes\n",
    "        #print(i, line)  # Debug line printing\n",
    "\n",
    "        words = line.split(\"&\")\n",
    "\n",
    "        for j, nr in enumerate(words[start_w:]):\n",
    "            nr_str = nr.strip(\" \\\\\")\n",
    "            rank_i = df_ranks.iloc[i, j]\n",
    "            new_nr = \"%s_{%i}\" % (nr_str, rank_i)\n",
    "\n",
    "            if rank_i == 1:\n",
    "                new_nr = \"$\\mathbf{%s}$\" % new_nr\n",
    "            else:\n",
    "                new_nr = \"$%s$\" % new_nr\n",
    "\n",
    "            words[j + start_w] = new_nr\n",
    "\n",
    "        new_line = \" & \".join(words) + \" \\\\\\\\\"\n",
    "\n",
    "        latex_lines[i + start] = new_line\n",
    "        \n",
    "    latex_lines.insert(start + 6, \"\\\\hline\")\n",
    "    latex_lines.insert(start + 6 + 6 + 1, \"\\\\hline\")\n",
    "\n",
    "    latex_lines.insert(i + start + 1 + 2, avg_ranks_str)\n",
    "    latex_lines = header_str + latex_lines[start:] + tail_str\n",
    "    latex_str_new = \"\\n\".join(latex_lines)\n",
    "    \n",
    "    return latex_str_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_latex(df, extra = \"_cw\"):\n",
    "    \n",
    "    value = \"pECE\"\n",
    "\n",
    "    latex_str = get_latex(df, methods_sorted, value = value, round_to=5, index=True, start_w = 1, start=4, max_is_better=False)\n",
    "\n",
    "    with open(\"results_dnn_%s%s.tex\" % (value.lower(), extra), \"w\") as f:\n",
    "        f.write(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latex(df_guo, extra = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_latex(df_cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from scipy.stats import friedmanchisquare\n",
    "import Orange\n",
    "\n",
    "def compute_friedmanchisquare(table):\n",
    "    '''\n",
    "    Example:\n",
    "        - n wine judges each rate k different wines. Are any of the k wines\n",
    "        ranked consistently higher or lower than the others?\n",
    "    Our Calibration case:\n",
    "        - n datasets each rate k different calibration methods. Are any of the\n",
    "        k calibration methods ranked consistently higher or lower than the\n",
    "        others?\n",
    "    This will output a statistic and a p-value\n",
    "    SciPy does the following:\n",
    "        - k: is the number of parameters passed to the function\n",
    "        - n: is the lenght of each array passed to the function\n",
    "    The two options for the given table are:\n",
    "        - k is the datasets: table['mean'].values).tolist()\n",
    "        - k is the calibration methods: table['mean'].T.values).tolist()\n",
    "    '''\n",
    "    return friedmanchisquare(*(table.T.values).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_critical_difference(avranks, num_datasets, names, filename,\n",
    "                               title=None, test='bonferroni-dunn'):\n",
    "    '''\n",
    "        test: string in ['nemenyi', 'bonferroni-dunn']\n",
    "         - nemenyi two-tailed test (up to 20 methods)\n",
    "         - bonferroni-dunn one-tailed test (only up to 10 methods)\n",
    "\n",
    "    '''\n",
    "    if len(avranks) > 10:\n",
    "        print('Forcing Nemenyi Critical difference')\n",
    "        test = 'nemenyi'\n",
    "    cd = Orange.evaluation.compute_CD(avranks, num_datasets, alpha='0.05',\n",
    "                                      test=test)\n",
    "    Orange.evaluation.graph_ranks(avranks, names, cd=cd, width=6,\n",
    "                                  textspace=1.5)\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(title, horizontalalignment='left')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_sorted_new = [\"Uncal\", \"TempS\", \"Dir-L2\", \"Dir-ODIR\", \"VecS\", \"MS-ODIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_cd_diagram(dfs_all, measure = \"pECE\", extra = \"_cw\", max_is_better = False, summary_path = \"cd_diagrams\"):\n",
    "\n",
    "    table = dfs_all.pivot_table(index=\"Name\", columns=\"Method\", values=measure)[methods_sorted]\n",
    "    table.index = index_new\n",
    "    table = table.reindex(models_sorted)\n",
    "    table.columns = methods_sorted_new\n",
    "    \n",
    "    if max_is_better:\n",
    "        table *= -1\n",
    "    \n",
    "    ranking_table_all = table.apply(rankdata, axis=1).mean()\n",
    "\n",
    "    ftest = compute_friedmanchisquare(table)\n",
    "    print('Friedman test on the full table of shape {}'.format(\n",
    "                np.shape(table)))\n",
    "    print(ftest)\n",
    "    \n",
    "    if not os.path.exists(summary_path):\n",
    "        print(\":/\")\n",
    "        os.makedirs(summary_path)\n",
    "        \n",
    "    export_critical_difference(avranks=ranking_table_all,\n",
    "                           num_datasets=len(table),\n",
    "                           names=table.columns,\n",
    "                           filename=os.path.join(summary_path,\n",
    "                                                 'crit_diff_' +\n",
    "                                                 measure + extra + '_v2.pdf'),\n",
    "                           title='(p-value = {:.2e}, #D = {})'.format(ftest.pvalue, len(table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test on the full table of shape (15, 6)\n",
      "FriedmanchisquareResult(statistic=16.05504587155968, pvalue=0.006688660141740905)\n",
      ":/\n"
     ]
    }
   ],
   "source": [
    "get_cd_diagram(df_cw, max_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman test on the full table of shape (15, 6)\n",
      "FriedmanchisquareResult(statistic=19.76454293628816, pvalue=0.0013834504944968717)\n"
     ]
    }
   ],
   "source": [
    "get_cd_diagram(df_guo, extra=\"\", max_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
